1) Данный пакет прост в освоении и настройке, у него хорошая документация и он обновляется по сей день.
Не засоряет код, так как сам создает свои папки не нарушая архитектуры и даже это можно сконфигурировать.
Из коробки умеет работать с чанками, что позволяет не засорять память, если файл слишком огромный. Для еще более нагруженных решений хорошо работает с Laravel Queues.
2) Я руководствовался базовыми правилами валидатора, для того, чтобы данные записались в бд и не вызвали ошибок. Класс описан так, что если попросят добавить новые валидаторы, это можно сделать быстро.
3) Я смотрел на время выполнения запроса с маленьким количеством данных и большим и какую нагрузку оно давало на приложение. Нагрузку на машину смотреть в оверлее докера.
4) Если будет 6000000 записей, то проблемы начнутся, потому что в моей реализации файл сначала парсится, потом все данные обрабатываются.\
Для реализации чего-то настолько огромного нужно будет импорт разбивать на чанки, чанки уже обрабатывать и сохранять.
Дополнительно выводить все в jobs, чтобы выполнялось на фоне.
Таким образом компесируется нагрузка на бд и на железо.
5) Однозначное улучшение, это разбить импорт на чанки. Очереди опционально.
Также для чистоты кода можно использовать DTO.
Я использовал Pusher, можно развернуть свой web socket сервер и конфигурировать его под свои нужды.
Возможно я слишком сильно разбил функционал по сервисам и нужно скомпоновать.
Работу с Редисом точно надо выносить отдельно, потому что он зашит в классе импотра, и переиспользование будет проблемой. Это же относится к вызовам Эвентов.
Валидатор данных хоть просто и расширяемый, при большом количестве проверок, он сильно раздуется. Его нужно разбивать на подгруппы валидаторов.